---
# Namespace for monitoring components
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/component: observability

---
# ServiceAccount for Prometheus
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring

---
# ClusterRole for Prometheus to discover services
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions", "apps"]
    resources:
      - deployments
      - replicasets
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - configmaps
    verbs: ["get"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]

---
# ClusterRoleBinding for Prometheus
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: monitoring

---
# ConfigMap for Prometheus configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'sparc-production'
        environment: 'production'

    # Alertmanager configuration
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
                - alertmanager:9093

    # Load rules once and periodically evaluate them
    rule_files:
      - '/etc/prometheus/rules/*.yaml'

    # Scrape configurations
    scrape_configs:
      # Prometheus self-monitoring
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      # SPARC services in the sparc namespace
      - job_name: 'sparc-services'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names: ['sparc']
        relabel_configs:
          # Only scrape pods with prometheus.io/scrape annotation
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: 'true'
          # Use the prometheus.io/path annotation value as the metrics path
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          # Use the prometheus.io/port annotation value as the port
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          # Add pod labels
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          # Add pod name
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
          # Add namespace
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          # Add service name from app label
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: replace
            target_label: service
          # Add component label
          - source_labels: [__meta_kubernetes_pod_label_component]
            action: replace
            target_label: component

      # Node exporter for infrastructure metrics
      - job_name: 'node-exporter'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__address__]
            regex: '(.*):10250'
            replacement: '${1}:9100'
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - source_labels: [__meta_kubernetes_node_name]
            action: replace
            target_label: instance

---
# ConfigMap for alert rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
data:
  sparc-service-alerts.yaml: |
    groups:
      - name: sparc_service_alerts
        interval: 30s
        rules:
          # Service down alert
          - alert: ServiceDown
            expr: up{job="sparc-services"} == 0
            for: 5m
            labels:
              severity: critical
              component: infrastructure
            annotations:
              summary: "Service {{ $labels.service }} is down"
              description: "Service {{ $labels.service }} in namespace {{ $labels.kubernetes_namespace }} has been down for more than 5 minutes"

          # High error rate
          - alert: HighErrorRate
            expr: |
              (
                sum(rate(http_requests_total{job="sparc-services",status=~"5.."}[5m])) by (service)
                /
                sum(rate(http_requests_total{job="sparc-services"}[5m])) by (service)
              ) > 0.05
            for: 5m
            labels:
              severity: warning
              component: application
            annotations:
              summary: "High error rate for service {{ $labels.service }}"
              description: "Service {{ $labels.service }} has error rate above 5% (current: {{ $value | humanizePercentage }})"

          # High latency
          - alert: HighLatency
            expr: |
              histogram_quantile(0.95,
                sum(rate(http_request_duration_seconds_bucket{job="sparc-services"}[5m])) by (service, le)
              ) > 0.5
            for: 10m
            labels:
              severity: warning
              component: performance
            annotations:
              summary: "High latency for service {{ $labels.service }}"
              description: "Service {{ $labels.service }} p95 latency is above 500ms (current: {{ $value | humanize }}s)"

          # High memory usage
          - alert: HighMemoryUsage
            expr: |
              (
                container_memory_usage_bytes{pod=~".*", namespace="sparc"}
                / 
                container_spec_memory_limit_bytes{pod=~".*", namespace="sparc"}
              ) > 0.9
            for: 10m
            labels:
              severity: warning
              component: resources
            annotations:
              summary: "High memory usage for pod {{ $labels.pod }}"
              description: "Pod {{ $labels.pod }} memory usage is above 90% (current: {{ $value | humanizePercentage }})"

          # High CPU usage
          - alert: HighCPUUsage
            expr: |
              (
                rate(container_cpu_usage_seconds_total{pod=~".*", namespace="sparc"}[5m])
                / 
                container_spec_cpu_quota{pod=~".*", namespace="sparc"} * 100000
              ) > 0.8
            for: 15m
            labels:
              severity: warning
              component: resources
            annotations:
              summary: "High CPU usage for pod {{ $labels.pod }}"
              description: "Pod {{ $labels.pod }} CPU usage is above 80% (current: {{ $value | humanize }}%)"

          # Pod restart
          - alert: PodRestartingTooOften
            expr: |
              increase(kube_pod_container_status_restarts_total{namespace="sparc"}[1h]) > 5
            for: 5m
            labels:
              severity: warning
              component: stability
            annotations:
              summary: "Pod {{ $labels.pod }} is restarting too often"
              description: "Pod {{ $labels.pod }} has restarted {{ $value }} times in the last hour"

---
# PersistentVolumeClaim for Prometheus data
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-data
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: fast-ssd

---
# Deployment for Prometheus
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/version: "2.47.0"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/component: monitoring
  template:
    metadata:
      labels:
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/component: monitoring
        app.kubernetes.io/version: "2.47.0"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: prometheus
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      containers:
        - name: prometheus
          image: prom/prometheus:v2.47.0
          imagePullPolicy: IfNotPresent
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--storage.tsdb.retention.time=30d'
            - '--storage.tsdb.retention.size=45GB'
            - '--web.console.libraries=/usr/share/prometheus/console_libraries'
            - '--web.console.templates=/usr/share/prometheus/consoles'
            - '--web.enable-lifecycle'
            - '--web.enable-admin-api'
          ports:
            - name: web
              containerPort: 9090
              protocol: TCP
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
            limits:
              cpu: 2000m
              memory: 4Gi
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: web
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /-/ready
              port: web
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: config
              mountPath: /etc/prometheus
            - name: rules
              mountPath: /etc/prometheus/rules
            - name: data
              mountPath: /prometheus
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 65534
            capabilities:
              drop:
                - ALL
      volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: rules
          configMap:
            name: prometheus-rules
        - name: data
          persistentVolumeClaim:
            claimName: prometheus-data

---
# Service for Prometheus
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
spec:
  type: ClusterIP
  ports:
    - name: web
      port: 9090
      targetPort: web
      protocol: TCP
  selector:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
  sessionAffinity: None

---
# ServiceMonitor for Prometheus self-monitoring (if using Prometheus Operator)
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: prometheus-self
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: monitoring
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/component: monitoring
  endpoints:
    - port: web
      interval: 30s
      path: /metrics